<!DOCTYPE html>
<html lang="fr-FR">

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320"><meta property="og:title" content="Loom - Part 2 - Blocking code">
<meta property="og:description" content="One of the biggest pain points I had learning about concurrent programming was the emphasis put on
Blocking, Non-blocking, Synchronous and Asynchronous code.
We&rsquo;ll touch on all four in the next parts of this series.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://www.monkeypatch.io/blog/2019/2019-12-18-loom-part-2-blocking/">

<meta property="og:image" content="https://www.monkeypatch.io/public/images/logos/logo-mkp-blue-x256.png">

<meta property="og:image" content="https://www.monkeypatch.io/images/logos/logo-mkp-head-blue-x126.png">

<meta property="og:image" content="https://www.monkeypatch.io/images/logo-monochrome.svg">
<meta property="article:published_time" content="2019-12-18T12:11:16+01:00">
<meta property="article:modified_time" content="2019-12-18T12:11:16+01:00"><meta property="og:site_name" content="MonkeyPatch">
<meta itemprop="name" content="Loom - Part 2 - Blocking code">
<meta itemprop="description" content="One of the biggest pain points I had learning about concurrent programming was the emphasis put on
Blocking, Non-blocking, Synchronous and Asynchronous code.
We&rsquo;ll touch on all four in the next parts of this series.">


<meta itemprop="datePublished" content="2019-12-18T12:11:16&#43;01:00">
<meta itemprop="dateModified" content="2019-12-18T12:11:16&#43;01:00">
<meta itemprop="wordCount" content="2986">



<meta itemprop="keywords" content="java,concurrency,loom,">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://www.monkeypatch.io/public/images/logos/logo-mkp-blue-x256.png">

<meta name="twitter:title" content="Loom - Part 2 - Blocking code">
<meta name="twitter:description" content="One of the biggest pain points I had learning about concurrent programming was the emphasis put on
Blocking, Non-blocking, Synchronous and Asynchronous code.
We&rsquo;ll touch on all four in the next parts of this series.">
<meta name="generator" content="Hugo 0.56.3">

<meta name="ROBOTS" content="INDEX, FOLLOW">

<title>MonkeyPatch  | Loom - Part 2 - Blocking code</title>


<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">






<link rel="stylesheet" href="https://www.monkeypatch.io/styles/main.62e4def08f0817473ef2abade8bc61175413e8ba5b2b4982c955a6e0a6722ef9.css">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">

<link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
    
    
    
    

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism-tomorrow.min.css" integrity="sha256-4S9ufRr1EqaUFFeM9/52GH68Hs1Sbvx8eFXBWpl8zPI=" crossorigin="anonymous">

</head>

<body class="page blog blog-2019-2019-12-18-loom-part-2-blocking">

    
    <header>
    
    <div class="menu">
        <div class="logo">
            <a href="https://www.monkeypatch.io/">
                <img alt="Monkey Patch" src="/images/logos/logo-monkey.svg">
            </a>
        </div>

        <nav class="lang">
            <ul>
                
                <li class="active">
                    <a href="https://www.monkeypatch.io/">FR</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/en/">FR</a>
                </li>
                
            </ul>
        </nav>

        <nav class="menu">
            <ul>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/expert/">Notre Expertise</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/about/">Notre Philo</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/careers/">Être Monkeys</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/jobs/">Nos Jobs</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/contact/">Contact</a>
                </li>
                
                <li class="">
                    <a href="https://www.monkeypatch.io/blog/">Blog</a>
                </li>
                
            </ul>
        </nav>

        <nav class="hamburger">
            <label for="menu-hamburger">
                <i class="fa fa-bars" aria-hidden="true"></i>
            </label>
        </nav>

    </div>
    <input type="checkbox" id="menu-hamburger">
    <nav class="menu-hamburger">
        <ul>
            
            <li class="">
                <a href="https://www.monkeypatch.io/expert/">Notre Expertise</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/about/">Notre Philo</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/careers/">Être Monkeys</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/jobs/">Nos Jobs</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/contact/">Contact</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/blog/">Blog</a>
            </li>
            
        </ul>
        <ul class="lang">
            
            <li class="active">
                <a href="https://www.monkeypatch.io/">FR</a>
            </li>
            
            <li class="">
                <a href="https://www.monkeypatch.io/en/">FR</a>
            </li>
            
        </ul>
    </nav>
</header>
    

    <main>
        <a id="top"></a>
        

<section class="post">
    <a id="top" name="top"></a>
    <h1>
        <span>Loom - Part 2 - Blocking code</span>
    </h1>


    <span class="date">
    December 
    18th,
    2019
</span>


    <div class="tags">
        
        
        <span>java</span>
        
        <span>concurrency</span>
        
        <span>loom</span>
        
    </div>

    <article><p>One of the biggest pain points I had learning about concurrent programming was the emphasis put on
<code>Blocking</code>, <code>Non-blocking</code>, <code>Synchronous</code> and <code>Asynchronous</code> code.<br>
We&rsquo;ll touch on all four in the next parts of this series.</p>

<blockquote>
<p>Part 2 in a series of articles about Project Loom.<br>
In this part we implement a proxy service, the easiest way possible.</p>

<p>The companion code repository is at <a href="https://github.com/arnaudbos/untangled">arnaudbos/untangled</a></p>

<p>If you&rsquo;d like you could head over to<br>
<a href="../2019-12-14-loom-part-0-rationale">Part 0 - Rationale</a><br>
<a href="../2019-12-14-loom-part-1-scheduling">Part 1 - It&rsquo;s all about Scheduling</a><br>
<a href="../2019-12-18-loom-part-2-blocking">Part 2 - Blocking code</a> (this page)<br>
<a href="../2019-12-23-loom-part-3-async">Part 3 - Asynchronous code</a><br>
<a href="../../2020/2020-05-08-loom-part-4-nio">Part 4 - Non-thread-blocking async I/O</a></p>
</blockquote>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/loom.jpg" alt="Loom" width="70%">
    
    
    <figcaption>
        <h6><em>Loom</em></h6>
        
    </figcaption>
    
</figure>



<hr>

<h2 id="a-simple-use-case">A simple use case</h2>

<p>After reading a lot I figured that implementing a simple use case would comfort my understandings and help me convey
what I wanted to explain. So here&rsquo;s a not totally made up, simple use case:</p>

<ol>
<li>clients need access to some restricted resources,</li>
<li>a proxying service will rate-limit the clients access, based on a token policy.</li>
</ol>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/demo-1.png" alt="Use case: A proxy server" width="70%">
    
    
    <figcaption>
        <h6><em>Use case: A proxy server</em></h6>
        
    </figcaption>
    
</figure>



<ol>
<li>A client addresses a download request to the proxy service.</li>
<li>The proxy service registers the request to a coordinator.</li>
<li>The coordinator is responsible for the scheduling logic using a priority queue. Its logic is irrelevant.</li>
<li>The coordinator responds either &ldquo;Unavailable&rdquo; or &ldquo;Available&rdquo;.</li>
<li>&ldquo;Unavailable&rdquo; means that the client can&rsquo;t download the resource just yet (responses&rsquo; payload contains a token).</li>
<li>The payload also contains an &ldquo;ETA&rdquo;, so the service can decide to abort or to retry, using the token to keep its place
in the coordinator&rsquo;s queue.</li>
<li>The payload also contains a &ldquo;wait&rdquo; time to rate-limit the retry requests to the coordinator.</li>
</ol>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/demo-2.png" alt="Use case: A proxy server" width="70%">
    
    
    <figcaption>
        <h6><em>Use case: A proxy server</em></h6>
        
    </figcaption>
    
</figure>



<ol start="8">
  <li>The proxy may have to retry a couple of times, on behalf of the client, but will eventually receive an "Available" response.</li>
  <li>With an "Available" response and the token contained in its payload, the proxy service can initiate a download request to the data source.</li>
  <li>The proxy service streams the content of the download request back to its client;</li>
  <li>While at the same time sending periodic "heartbeat" requests to the coordinator to ensure its token is not revoked.</li>
</ol>

<p>We are going to use this scenario in the next parts of the series. We will implement this proxy service in
various ways, simulate a few (200) clients connecting simultaneously and see the pros and cons of each implementation.</p>

<blockquote>
<p>Bear in mind that this is not a benchmark, it&rsquo;s just an experiment! 200 clients is a really low number
but is enough to observe a few interesting things.</p>
</blockquote>

<h2 id="first-implementation">First implementation</h2>

<p>I am now going to show you the easiest way I came up with to implement this proxy service.</p>

<p>You can find the complete source code for this sample <a href="https://github.com/arnaudbos/untangled/blob/master/hawaii/src/main/java/io/monkeypatch/untangled/Chapter01_SyncBlocking.java">here</a>.</p>

<p><code>getThingy()</code> is the download endpoint in this example. Each client &ldquo;connecting&rdquo; to the proxy hits this method:</p>

<pre><code class="language-java">private void getThingy() throws EtaExceededException, IOException {
    println(&quot;Start getThingy.&quot;);

    try {
①      Connection.Available conn = getConnection();
        println(&quot;Got token, &quot; + conn.getToken());

        Thread pulse = makePulse(conn);
②      try (InputStream content = gateway.downloadThingy()) {
③          pulse.start();

④          ignoreContent(content);
        } catch (IOException e) {
            err(&quot;Download failed.&quot;);
            throw e;
        }
        finally {
⑤          pulse.interrupt();
        }
    } catch (InterruptedException e) {
        // D'oh!
        err(&quot;Task interrupted.&quot;);
        Thread.currentThread().interrupt();
        throw new RuntimeException(e);
    }
    println(&quot;Download finished&quot;)
}
</code></pre>

<ol>
<li>We retrieve an &ldquo;Available&rdquo; connection <code>conn</code> from the coordinator</li>
<li>We initiate the download request to the data source (called <code>gateway</code> in this example).</li>
<li>Once the download has begun we start the heartbeat requests (<em>pulse</em> thread).</li>
<li>While at the same time consuming the content (<code>InputStream</code>, here we simply drop it, but in a real scenario we
would forward to the client).<br></li>
<li>Once the download ends (successfully or not) we stop sending heartbeat requests and the call ends.</li>
</ol>

<p>Maybe you were hoping to see some kind of framework here, some <em>@Controller</em> or <em>@GET</em> annotation perhaps?</p>

<p>In this series, I&rsquo;m not going to bother with a framework. Because the number of clients is so small and this is not a
benchmark, I am just simulating the client calls from within the same JVM.</p>

<p>This way, I am able to use the kind of <code>ExecutorService</code> I want for each implementation, in order to outline a few
things. This executor and its thread pool will simulate the Web Server thread pool that could be found inside any Web
Framework. In the end it is more illustrative to have it directly at hand.</p>

<p>Let&rsquo;s simulate a few clients, shall we?</p>

<pre><code class="language-java">CompletableFuture&lt;Void&gt;[] futures = new CompletableFuture[MAX_CLIENTS];
for(int i=0; i&lt;MAX_CLIENTS; i++) {
    int finalI = i;
    futures[i] = new CompletableFuture&lt;&gt;();
    elasticServiceExecutor.submit(() -&gt; {
        try {
            getThingy(finalI);
            futures[finalI].complete(null);
        } catch (EtaExceededException e) {
            err(&quot;Couldn't getThingy because ETA exceeded: &quot; + e);
            futures[finalI].completeExceptionally(e);
        } catch (Exception e) {
            err(&quot;Couldn't getThingy because something failed: &quot; + e);
            futures[finalI].completeExceptionally(e);
        }
    });
}
</code></pre>

<p>In this implementation, <code>elasticServiceExecutor</code> is a &ldquo;cached&rdquo; <code>ThreadPoolExecutor</code>, and I will explain why in a
little bit.</p>

<pre><code class="language-java">elasticServiceExecutor =
    Executors.newCachedThreadPool(new PrefixedThreadFactory(&quot;service&quot;));
</code></pre>

<p>We have a &ldquo;Web Server&rdquo;, clients and our download controller.</p>

<p>There are a few things to unpack from this controller.<br>
Let&rsquo;s start with the least interesting bit first, <code>makePulse</code>:</p>

<pre><code class="language-java">private Thread makePulse(Connection.Available conn) {
    return new Thread(() -&gt; {
        while(!Thread.currentThread().isInterrupted()) {
            try {
                // Periodic heartbeat
                Thread.sleep(2_000L);

                println(&quot;Pulse!&quot;);
                coordinator.heartbeat(conn.getToken());
            } catch (InterruptedException e) {
                // D'oh!
                Thread.currentThread().interrupt();
            }
        }
    });
}
</code></pre>

<p>Nothing fancy here: sleep for a while, send a request, sleep for a while, send a request, &hellip;</p>

<p>You may have noticed that <em>getThingy</em> uses the <code>gateway</code> service to talk to the data source and that <em>makePulse</em> uses
the <code>coordinator</code> service to talk to the coordinator.<br>
So what is this <code>getConnection</code> method and why does <em>getThingy</em> not use <code>coordinator</code> directly?</p>

<p>Because of the retry logic we&rsquo;ve talked about before!<br>
<code>getConnection</code> is actually a helper to handle
the <em>Unavailable</em> responses from the coordinator and only return when an <em>Available</em> response has been received. Here&rsquo;s
the code:</p>

<pre><code class="language-java">private Connection.Available getConnection()
    throws EtaExceededException, InterruptedException
{
①  return getConnection(0, 0, null);
}

private Connection.Available getConnection(long eta, long wait, String token)
    throws EtaExceededException, InterruptedException
{
    for(;;) {
        if (eta &gt; MAX_ETA_MS) {
            throw new EtaExceededException();
        }

        if (wait &gt; 0) {
            Thread.sleep(wait);
        }

        println(&quot;Retrying download after &quot; + wait + &quot;ms wait.&quot;);
    
②      Connection c = coordinator.requestConnection(token);
        if (c instanceof Connection.Available) {
④          return (Connection.Available) c;
        }
③      Connection.Unavailable unavail = (Connection.Unavailable) c;
        eta = unavail.getEta();
        wait = unavail.getWait();
        token = unavail.getToken();
    }
}
</code></pre>

<ol>
<li>We start with initial <code>eta</code> and <code>wait</code> times at zero and no token (<code>null</code>).</li>
<li>We try to get a grant from the coordinator.</li>
<li>If the coordinator rejects us with an <code>Unavailable</code> response, we update the <em>eta</em>, <em>wait</em> and <em>token</em> and loop;</li>
<li>Otherwise we can return the <code>Available</code> response.</li>
</ol>

<p>As I said: the <strong>easiest</strong> implementation I could come up with.</p>

<p><strong>Any Java developer from junior to expert can understand this code!</strong><br>
It is <em>classic</em>, <em>old</em>, <em>boring</em>, <em>imperative</em> Java code which <strong><em>does the job</em></strong>.</p>

<p>And <em>easy</em> is important, right? I&rsquo;m 100% confident that all of you know what the service does and how it does it. We
can now build from here with all the subsequent implementations, using different paradigms and APIs.</p>

<p>Before that, let&rsquo;s now see what this code <em>actually</em> does.</p>

<h2 id="profiling">Profiling</h2>

<p>The first tool I turned to is <a href="https://visualvm.github.io/">VisualVM</a>. In the absence of metrics from the code, defaulting to VisualVM gives a basic
understanding of the behaviour of a JVM application regarding its thread and objects allocation, CPU utilization, GC
pressure, etc.</p>

<h3 id="cpu-usage">CPU usage</h3>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/impl1-cpu.png" alt="CPU utilization is low" width="70%">
    
    
    <figcaption>
        <h6><em>CPU utilization is low</em></h6>
        
    </figcaption>
    
</figure>



<p>CPU usage is really limited in this example (at a guess, I&rsquo;d say the 95 percentile is less than 3% with an outlier at
about 8% for a very short time during startup). Which makes sense, right?</p>

<p>Indeed, this use case is designed to be <em>I/O bound</em>: it&rsquo;s not like we&rsquo;re computing any math. Instead
we send a bunch or requests, wait a little in between, then some more requests to forward content from
buffers and&hellip; Done.</p>

<p>None of this requires a lot of CPU power so this screenshot should not be surprising. In fact, it will be the same
for all the other implementations we will see in the next parts, so I am not going to display it again.</p>

<p>Looking at the threads is much more interesting.</p>

<h3 id="threads">Threads</h3>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/impl1-threads.png" alt="We&#39;re creating a lot of threads" width="70%">
    
    
    <figcaption>
        <h6><em>We&#39;re creating a lot of threads</em></h6>
        
    </figcaption>
    
</figure>



<p>We can see in the figure above that when the application starts, meaning &ldquo;when our clients connect&rdquo;, it is going to
create a first batch of about 200 threads. And then progressively start 200 more over a period of about 5 seconds.</p>

<p>The last 200 are pretty obvious given the implementation of <code>makePulse</code>: once the proxy begins to receive <code>Available</code>
responses from the coordinator, it starts the threads instantiated by the calls to <code>makePulse</code>. This is just an
implementation detail. A wrong one for sure, but a minor detail.</p>

<p>What should be more intriguing are the first 200 (the 10 additional ones are created by the JVM itself). Why are
200 clients creating 200 threads?</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/impl1-threads-running.png" alt="200&#43; threads &#34;running&#34;" width="70%">
    
    
    <figcaption>
        <h6><em>200&#43; threads &#34;running&#34;</em></h6>
        
    </figcaption>
    
</figure>



<p>They all seem pretty busy (green means &ldquo;running&rdquo; in VisualVM), which is weird. We&rsquo;ve seen that CPU usage is really low,
so our cores don&rsquo;t actually do much in practice!</p>

<p>We must take a closer look at what those threads actually do. Let&rsquo;s get a <em>thread dump</em>.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/impl1-thread-dump.png" alt="Typical thread from this application" width="70%">
    
    
    <figcaption>
        <h6><em>Typical thread from this application</em></h6>
        
    </figcaption>
    
</figure>



<p>This screenshot shows only one of the many threads described in the thread dump because they all look alike.</p>

<p>The typical thread in this application seems to be running this <code>SocketDispatch#read0</code> native method. And they aren&rsquo;t
&ldquo;just&rdquo; running this method but in fact spending <strong>most of their time</strong> running it.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/impl1-flame.png" alt="Flame Graph" width="70%">
    
    
    <figcaption>
        <h6><em>Flame Graph</em></h6>
        
    </figcaption>
    
</figure>



<p>This <a href="http://www.brendangregg.com/flamegraphs.html">flame graph</a> was acquired using <a href="https://github.com/jvm-profiling-tools/async-profiler">async-profiler</a> and shows that time spent running <code>SocketDispatcher#read0</code>&rsquo;s
underlying <code>read</code> system call dominates our application.</p>

<p>If we track its call stack to find its origin, we stumble upon <code>lambda$run$1</code>. Which, in fact, is the call to the
astutely named <code>blockingRequest</code> method, inside of the <em>gateway</em> service:</p>

<pre><code class="language-java">class SyncGatewayService {
    InputStream downloadThingy() throws IOException {
        return blockingRequest(
            &quot;http://localhost:7000&quot;,
            String.format(HEADERS_TEMPLATE,
                          &quot;GET&quot;,
                          &quot;download&quot;,
                          &quot;text/*&quot;,
                          String.valueOf(0))
        );
    }
}
</code></pre>

<p>Without further suspense, here&rsquo;s its code:</p>

<pre><code class="language-java">public static InputStream blockingRequest(String url, String headers)
    throws IOException
{
    println(&quot;Starting request to &quot; + url);
    URL uri = new URL(url);
    SocketAddress serverAddress =
        new InetSocketAddress(uri.getHost(), uri.getPort());
    SocketChannel channel = SocketChannel.open(serverAddress);
    ByteBuffer buffer = ByteBuffer.wrap(
        (headers + &quot;Host: &quot; + uri.getHost() + &quot;\r\n\r\n&quot;).getBytes()
    );
    do {
        channel.write(buffer);
    } while(buffer.hasRemaining());

    return channel.socket().getInputStream();
}
</code></pre>

<p>You can see in the call chain that <code>read0</code> originates from calling <code>InputStream#read</code>. The <em>InputStream</em> itself is
obtained from the <code>SocketChannel</code>. And this, dear reader, is the ugly detail that makes this application not
efficient and is the reason why we end up with as many threads as clients.</p>

<p>Because this socket channel (analogous to a <a href="https://en.wikipedia.org/wiki/File_descriptor">file descriptor</a>) is written to and read from in <strong>blocking mode</strong>.
What&rsquo;s a blocking call and why is it bad?<br>
Let&rsquo;s talk about what happens when one of our threads&rsquo; runnable contains a thread blocking call.</p>

<h2 id="context-switches">Context switches</h2>

<h3 id="what-they-are">What they are</h3>

<p>For the sake of simplicity, let&rsquo;s assume that our CPUs run two kinds of instructions.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/engine.png" alt="Legend" width="70%">
    
    
    <figcaption>
        <h6><em>Legend</em></h6>
        
    </figcaption>
    
</figure>



<p>Instructions coming from what we&rsquo;ll call our &ldquo;user code&rdquo;, represented by the triangle, hexagon, square and round shapes.<br>
And instructions coming from the kernel whose goals are to enforce scheduling policies represented by the circle and
cross shapes.<br>
The CPU will be represented by a <a href="https://en.wikipedia.org/wiki/Wankel_engine">Wankel engine</a>.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-1.png" alt="Kernel threads" width="70%">
    
    
    <figcaption>
        <h6><em>Kernel threads</em></h6>
        
    </figcaption>
    
</figure>



<p>On the JVM, the threads we manipulate are actually kernel threads. The threads which are instantiated and managed by
the various flavors of <code>ExecutorService</code>, available via the helper <code>java.util.concurrent.Executors</code>, are an abstraction
over native threads, with additional thread pool logic, tasks queues management and scheduling mechanisms.</p>

<p>As said earlier, the executor I&rsquo;ve used in this implementation is a &ldquo;cached&rdquo; <code>ThreadPoolExecutor</code>.</p>

<pre><code class="language-java">elasticServiceExecutor =
    Executors.newCachedThreadPool(new PrefixedThreadFactory(&quot;service&quot;));
</code></pre>

<p>This executor handles an initial pool of threads, as well as a task queue (<code>SynchronousQueue</code>).<br>
It also has a reference to a <code>ThreadFactory</code>, because this executor will try to match each <code>Runnable</code>, that is submitted
to it via its <code>submit</code> method, to a runnable thread in its pool. If no thread is available to run the next <em>Runnable</em> in
the queue, it will use the <em>ThreadFactory</em> to create a new thread and hand the <em>Runnable</em> object to it.</p>

<p>The threads thus created are managed by the kernel, which itself manages its own priority queue and acts according to
its scheduling policy (we&rsquo;ve talked about this in the <a href="../2019-12-14-loom-part-1-scheduling">part 1 of this series</a>). The priority queue shown in the
illustration above is the kernel&rsquo;s.</p>

<p>So, in a nutshell, when a thread is scheduled to run, its instructions are executed one after the other by the CPU.<br>
Up until it finishes, or a blocking call is made.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-2.png" alt="Close Encounters of the Blocking Kind" width="70%">
    
    
    <figcaption>
        <h6><em>Close Encounters of the Blocking Kind</em></h6>
        
    </figcaption>
    
</figure>



<p>In the illustration above, the &ldquo;round&rdquo; instructions come from the currently scheduled thread. We can see that the
current instruction is, in fact, a blocking OS call (syscall, such as <code>read</code>).</p>

<p>What will actually happen here, is a <strong>context switch</strong>. Because the thread is currently trying to execute an
action <em>outside</em> its current <a href="https://en.wikipedia.org/wiki/Protection_ring">protection ring</a>.</p>

<p>JVM applications run in <em>user space</em> (ring 3) to ensure memory and hardware protection.<br>
The kernel runs in <em>kernel space</em> (ring 0). It is responsible to ensure computer security and that processes behave,
basically.</p>

<p>When executing syscalls, such as blocking <code>read</code>s, <em>kernel space</em> access level is required. Kernel instructions will be
run on behalf of the &ldquo;user code&rdquo; and will, for instance, ensure that this thread does not hold onto the CPU while
waiting for its call to return and that another thread has a chance to run in the mean time, hence ensuring compliance
with the scheduling policies.</p>

<p>For the sake of simplicity, I&rsquo;m representing a context switch as a 2-step process.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-3.png" alt="A context switch" width="70%">
    
    
    <figcaption>
        <h6><em>A context switch</em></h6>
        
    </figcaption>
    
</figure>



<p>During the first step, the kernel is going to <em>suspend</em> the execution of the current thread. In order to do this,
it is going to save a few things, such as the current instruction or process counter (on which instruction did the
thread pause), the thread&rsquo;s current call stack, the state of CPU registers it was accessing, etc.</p>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-4.png" alt="1/2: save execution state" width="70%">
    
    
    <figcaption>
        <h6><em>1/2: save execution state</em></h6>
        
    </figcaption>
    
</figure>



<p>The kernel is going to save all this in a data structure (see <a href="https://www.tutorialspoint.com/what-is-process-control-block-pcb">PCB</a>, for Process Control Block), and put the thread
back into the priority queue.</p>

<blockquote>
<p>Also for the sake of simplicity, I am representing the &ldquo;not ready&rdquo; state of a thread as if flagged and put back into
a priority queue. But the actual logic may be more complicated, including several distinct queues for different
&ldquo;waiting&rdquo; purposes or any arbitrary logic as kernel developers see fit.</p>
</blockquote>


<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-5.png" alt="2/2: save execution state" width="70%">
    
    
    <figcaption>
        <h6><em>2/2: save execution state</em></h6>
        
    </figcaption>
    
</figure>



<p>In the second step, the kernel decides which thread should be scheduled next, according to its policies, and this thread
is allocated to the CPU. If this thread had been scheduled before, its state would have to be restored first.</p>

<p>This thread itself may contain instructions pointing at a blocking syscall, which would trigger a new context switch,
and so on and so forth until eventually the result of the blocking syscall made by the round instruction above is
available and this thread is scheduled again.</p>

<p>
</p><figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-6.png" width="70%">
    
    
</figure>



<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-7.png" width="70%">
    
    
</figure>



<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-8.png" width="70%">
    
    
</figure>



<figure style="text-align: center;">
    
        <img src="https://i-rant.arnaudbos.com/img/loom/context-switch-9.png" width="70%">
    
    
</figure>

<p></p>

<p>Now it&rsquo;s time to connect the dots and understand why blocking calls deserve such hatred.</p>

<h3 id="why-they-are-bad">Why they are bad</h3>

<p>One of the blog posts I like the most to explain this issue is
<em>&ldquo;Little&rsquo;s Law, Scalability and Fault Tolerance: The OS is your bottleneck (and what you can do about it)&rdquo;</em> by
<a href="https://twitter.com/pressron" title="pressron" target="_blank">@pressron</a>.</p>


<figure style="text-align: center;">
    <a target="_blank" href="https://web.archive.org/web/20191122044527/https://blog.paralleluniverse.co/2014/02/04/littles-law/">
        <img src="https://i-rant.arnaudbos.com/img/loom/little.png" alt="Little&#39;s Law, Scalability and Fault Tolerance: The OS is your bottleneck (and what you can do about it" width="70%">
    </a>
    
    <figcaption>
        <h6><em>Little&#39;s Law, Scalability and Fault Tolerance: The OS is your bottleneck (and what you can do about it</em></h6>
        
    </figcaption>
    
</figure>



<p>I&rsquo;m trying to do half as good in this series, so I strongly suggest that you take a look at it and read <em>at least</em> the
first 3 parts of the article: <em>&ldquo;Our Little Service&rdquo;</em>, <em>&ldquo;Little’s Law&rdquo;</em> and <em>&ldquo;What Dominates the Capacity&rdquo;</em>.</p>

<p>It explains that the number of connections our services can handle, when executing blocking code, is
not limited by the number of network connections our OS can keep open, but by the number of threads we create.<br>
Each kernel thread stack takes memory space and thread scheduling (context switches explained above) wastes CPU cycles,
induce CPU cache misses and adds latency to requests.</p>

<blockquote>
<p>Allowing the software to spawn thread willy-nilly may bring our application to its knees, so we usually set a hard
limit on the number of threads we let the application spawn.<br>
— R. Pressler</p>
</blockquote>

<p>So we know that we can&rsquo;t let the number of threads grow too much.<br>
But why is this code creating one thread-per-connection (not to mention the additional &ldquo;pulsing&rdquo; thread)?</p>

<p>The answer is: because of the cached <code>ThreadPoolExecutor</code>!<br>
As I said:</p>

<blockquote>
<p>If no thread is available to run the next <em>Runnable</em> in the queue, it will use the <em>ThreadFactory</em> to create a new
thread and hand the <em>Runnable</em> object to it.</p>
</blockquote>

<p>In this implementation, each request issues blocking writes and reads to and from the <code>SocketChannel</code>.<br>
Each of these calls lead to context switches during which the current thread will be paused.<br>
So connection requests added to the <code>ThreadPoolExecutor</code> waiting queue will quickly drain the number of threads
cached in the pool, because they are paused!<br>
This triggers the creation of more threads by the executor and boom!</p>

<p>We could use a different executor, such as <code>Executors.newFixedThreadPool(int, ThreadFactory)</code> in order to <em>&ldquo;limit the
number of threads we let the application spawn&rdquo;</em>. By doing so we explicitly limit the number of connections our service
can handle.</p>

<blockquote>
<p>We could, of course, buy more servers, but those cost money and incur many other hidden costs. We might be
particularly reluctant to buy extra servers when we realize that software is the problem, and those servers we
already have are under-utilized.<br>
— R. Pressler</p>
</blockquote>

<h2 id="conclusion">Conclusion</h2>

<p>This part of the series presented a use case from which we can build upon and
experiment. The goal is to find acceptable solutions to blocking calls and scalability issues.</p>

<p>I hope you understand a little more about blocking calls and context switches after reading this.</p>

<p>In the <a href="../2019-12-23-loom-part-3-async">next part</a>, we will take a look at asynchronous calls.</p></article>

    <div class="authors">
        
        <div class="author">
            <a href="https://twitter.com/arnaud_bos" rel="author">
                <img src="https://ca.slack-edge.com/T1H5KD6N6-U30C1P23G-a63601ba6c7d-512" alt="Arnaud bos">
                <span>Arnaud bos</span>
            </a>
        </div>
        
    </div>
</section>


<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "monkeypatchblog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




        
        <footer class="top">
    <div>
      <h3>Rester en contact</h3>
      <p>
        <a class="contact icon-map" href="/contact">
          <i class="fa fa-map-marker" aria-hidden="true"></i>
          <img src="/images/icons/Toulouse.png" alt="Toulouse">
        </a>
      </p>
      <p>
        <i class="fa fa-envelope-o" aria-hidden="true"></i>
        <a class="mail" href="mailto:contact@monkeypatch.io">contact@monkeypatch.io</a>
      </p>
    </div>
    <div class="social-network">
      <h3>Réseaux sociaux</h3>
      <ul class="social">
        <li>
          <a href="https://twitter.com/monkeypatch_io">
            <i class="fa fa-twitter" aria-hidden="true"></i>
          </a>
        </li>
        <li>
          <a href="https://www.linkedin.com/company/monkeypatch-io">
            <i class="fa fa-linkedin" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
    </div>
  
</footer>

<footer class="bottom">
  <div>
    Copyright @ 2019 MonkeyPatch -<a href="/terms">Termes et conditions</a>
  </div>
  <div>
    Made with <i class="fa fa-heart" aria-hidden="true"></i> In Toulouse
  </div>
  <a class="goToTop" href="#top">
    <i class="fa fa-caret-up" aria-hidden="true"></i>
  </a>
</footer>

        
    </main>


<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KGGFWH');</script>


<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KGGFWH" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <script src="/scripts/modernizr-custom.js"></script>
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-haskell.min.js" integrity="sha256-MxfNlM5EW2pm9DZPWGvreAHxKNF8NK8DaLSVVtG+MjE=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-clojure.min.js" integrity="sha256-eGVrzVqJ/GigoW8fpafNd5j00+zIESDj7FeJcrBUlrA=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-kotlin.min.js" integrity="sha256-BLmzS+mVDv8mg8ciLO7Lxoz1vAYhFtyboFOT0EMY+lg=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-c.min.js" integrity="sha256-POQgKdZt7XGlcjT5opjx6fXs/Pt4eao8x7Q8JRaa/1A=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-brainfuck.min.js" integrity="sha256-VMnAWpm0qsoKYhwjGWpbpIFoEqmKFqgRMvrsPe4SLA8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-lolcode.js" integrity="sha256-GfPLGNDlIwgQKINyzfQdNvX/cI3Pm9/4nQRGez7eMtc=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-typescript.min.js" integrity="sha256-m2ghaPy1JKNwDlCG/ObigLWw9/7qGHvUhoXp6odkcTI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-json.min.js" integrity="sha256-oA5rMHeAX+cg/CdcQ0VHmIqqw/IW4o2KAUEjo4QvShs=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-yaml.min.js" integrity="sha256-pxsoS7PqPuy6D5T0Dq2PEXKJ5SRlIkdG8hpoMxQ0YlM=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/components/prism-java.min.js" integrity="sha256-4jBV//QjNNXvyK55J0R2NwTbl2SAzk/4DHBynIhrxWQ=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.20.0/components/prism-rust.min.js" integrity="sha512-a+IgkN5sZbEosACcEWe/sM44yttZ31//JRCMMJ/iJvFqyMf5BFDTwClDikRSq9IFNCF5arl3VXl+43PIh+z77A==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.20.0/components/prism-toml.min.js" integrity="sha512-nR+DujZm33eiRbZSfMapBdGw+1a8yQCknJxCkdSqxWunDODhOv35GVaU1zUM1vqO0iHL86LRV9EGNi7EkjSFkw==" crossorigin="anonymous"></script>


<script>
Array.from(document.querySelectorAll(".post article [id]"))
    .forEach(function (elt) {
        var id = elt.getAttribute("id");
        var content = elt.textContent;
        elt.innerHTML = '<a class="anchor" href="#' + id + '">' + content + '</a>';
    });
</script>

<script>
    window.twttr = (function (d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0],
            t = window.twttr || {};
        if (d.getElementById(id)) return t;
        js = d.createElement(s);
        js.id = id;
        js.src = "https://platform.twitter.com/widgets.js";
        fjs.parentNode.insertBefore(js, fjs);

        t._e = [];
        t.ready = function (f) {
            t._e.push(f);
        };

        return t;
    }(document, "script", "twitter-wjs"));
</script>

</body>

</html>